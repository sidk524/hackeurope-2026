{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small CNN — MNIST Classification with Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# observer.py lives in the parent directory (neural_network/)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n",
    "from observer import Observer, ObserverConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "lr = 1e-3\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Observer] Initialized | project=1 | run=run_20260221_200204 | device=cpu\n",
      "[Observer] Backend session created | session_id=5\n",
      "[Observer] Hyperparameters logged: ['batch_size', 'num_epochs', 'learning_rate', 'optimizer', 'dataset', 'seed', 'device']\n"
     ]
    }
   ],
   "source": [
    "observer_config = ObserverConfig(\n",
    "    track_profiler=True,\n",
    "    profile_every_n_steps=100,  # profile every 100th step (0, 100, 200, ...)\n",
    "    track_memory=True,\n",
    "    track_throughput=True,\n",
    "    track_loss=True,\n",
    "    track_console_logs=True,\n",
    "    track_error_logs=True,\n",
    "    track_hyperparameters=True,\n",
    "    track_system_resources=True,\n",
    "    track_layer_graph=True,\n",
    ")\n",
    "\n",
    "observer = Observer(\n",
    "    project_id=\"1\",\n",
    "    config=observer_config,\n",
    ")\n",
    "\n",
    "observer.log_hyperparameters({\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": lr,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"dataset\": \"MNIST\",\n",
    "    \"seed\": seed,\n",
    "    \"device\": device,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60,000\n",
      "Test samples:     10,000\n",
      "Batches per epoch: 938\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Test samples:     {len(test_dataset):,}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Small convolutional network for MNIST.\n",
    "\n",
    "    Architecture:\n",
    "      Conv2d(1,16,3,pad=1) -> ReLU -> MaxPool(2)\n",
    "      Conv2d(16,32,3,pad=1) -> ReLU -> MaxPool(2)\n",
    "      Flatten -> Linear(32*7*7, 128) -> ReLU -> Linear(128, 10)\n",
    "\n",
    "    forward(x, targets=None) returns (logits, loss) to match\n",
    "    Observer.profile_step() which calls model(x, y).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 16, 14, 14)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, 7, 7)\n",
    "        x = x.view(x.size(0), -1)             # (B, 32*7*7)\n",
    "        x = F.relu(self.fc1(x))               # (B, 128)\n",
    "        logits = self.fc2(x)                   # (B, 10)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 206,922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Observer] Model registered | 206,922 params (0.21M) | 4 param layers\n",
      "[Observer] Model registered in backend | model_id=5\n"
     ]
    }
   ],
   "source": [
    "model = SmallCNN().to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "\n",
    "observer.register_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Compute average loss and accuracy on a DataLoader.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, loss = model(x, y)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    model.train()\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2026-02-21 20:02:04 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2026-02-21 20:02:04 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:04 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:06 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:06 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:06 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:07 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:07 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:07 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:08 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:08 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:08 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:10 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:10 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:10 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:11 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:11 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:11 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:12 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:12 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:12 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:13 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:13 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:13 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:15 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:15 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:15 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:16 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:16 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:16 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[Observer] Registering step 0 in backend\n",
      "[Observer] Step 0 registered in backend | step_id=5\n",
      "[Observer] Awaiting backend status for session 5...\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: running\n",
      "[Observer] --- Step 0 done | 13.29s | loss=0.169798 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss=0.1698  val_loss=0.0564  val_acc=0.9809  (24.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2026-02-21 20:02:29 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:29 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:29 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:30 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:30 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:30 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:31 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:31 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:31 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:32 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:32 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:32 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:33 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:33 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:33 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:35 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:35 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:35 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:36 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:36 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:36 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:37 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:37 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:37 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:38 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:38 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:38 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[Observer] Registering step 1 in backend\n",
      "[Observer] Step 1 registered in backend | step_id=6\n",
      "[Observer] Awaiting backend status for session 5...\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: pending\n",
      "[Observer] Session status: running\n",
      "[Observer] --- Step 1 done | 12.73s | loss=0.052465 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.0525  val_loss=0.0363  val_acc=0.9877  (46.9s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2026-02-21 20:02:51 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:51 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:51 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:52 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:52 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:52 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:54 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:54 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:54 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:55 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:55 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:55 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:56 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:56 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:56 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:57 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:57 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:57 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:02:58 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:02:58 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:02:58 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2026-02-21 20:03:00 29268:1091655 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2026-02-21 20:03:00 29268:1091655 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2026-02-21 20:03:00 29268:1091655 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m observer\u001b[38;5;241m.\u001b[39mstep(global_step, loss, batch_size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     22\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    390\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "training_start = time.time()\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if observer.should_profile(global_step):\n",
    "            logits, loss = observer.profile_step(model, x, y)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            logits, loss = model(x, y)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        observer.step(global_step, loss, batch_size=x.size(0))\n",
    "        global_step += 1\n",
    "\n",
    "    # Validation at end of each epoch\n",
    "    val_loss, val_acc = evaluate(model, test_loader)\n",
    "    step_report = observer.flush(val_metrics={\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "\n",
    "    elapsed = time.time() - training_start\n",
    "    print(\n",
    "        f\"Epoch {epoch}: \"\n",
    "        f\"train_loss={step_report['loss']['train_mean']:.4f}  \"\n",
    "        f\"val_loss={val_loss:.4f}  val_acc={val_acc:.4f}  \"\n",
    "        f\"({elapsed:.1f}s)\"\n",
    "    )\n",
    "\n",
    "training_time = time.time() - training_start\n",
    "print(f\"\\nTraining completed in {training_time:.2f}s ({training_time/60:.2f} min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"Final test loss:     {test_loss:.4f}\")\n",
    "print(f\"Final test accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observer Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = observer.export(os.path.join(\"observer_reports\", f\"{observer.run_id}.json\"))\n",
    "\n",
    "# ── Print summary ──\n",
    "summary = report[\"summary\"]\n",
    "print(\"=\" * 60)\n",
    "print(\"OBSERVER SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total steps recorded:   {summary.get('total_steps', 0)}\")\n",
    "print(f\"Total training time:    {summary.get('total_duration_s', 0):.2f}s\")\n",
    "\n",
    "if \"loss_trend\" in summary:\n",
    "    lt = summary[\"loss_trend\"]\n",
    "    print(f\"\\nLoss trend:\")\n",
    "    print(f\"  First interval:  {lt['first']:.4f}\")\n",
    "    print(f\"  Last interval:   {lt['last']:.4f}\")\n",
    "    print(f\"  Best:            {lt['best']:.4f}\")\n",
    "    print(f\"  Improved:        {lt['improved']}\")\n",
    "\n",
    "if \"avg_tokens_per_sec\" in summary:\n",
    "    print(f\"\\nAvg throughput:  {summary['avg_tokens_per_sec']:.0f} tokens/sec\")\n",
    "\n",
    "if \"profiler_highlight\" in summary:\n",
    "    ph = summary[\"profiler_highlight\"]\n",
    "    print(f\"\\nProfiler highlight:\")\n",
    "    print(f\"  Top operation:       {ph.get('top_op', 'N/A')}\")\n",
    "    print(f\"  Top op % of total:   {ph.get('top_op_pct', 0):.1f}%\")\n",
    "    print(f\"  Fwd/Bwd time ratio:  {ph.get('fwd_bwd_ratio', 'N/A')}\")\n",
    "\n",
    "# ── Print per-step profiler categories ──\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROFILER: OPERATION CATEGORIES (last step)\")\n",
    "print(\"=\" * 60)\n",
    "for step_rec in reversed(report[\"steps\"]):\n",
    "    if \"profiler\" in step_rec:\n",
    "        cats = step_rec[\"profiler\"].get(\"operation_categories\", {})\n",
    "        for cat_name, cat_data in sorted(cats.items(), key=lambda x: -x[1][\"cpu_time_ms\"]):\n",
    "            print(f\"  {cat_name:<20s}  {cat_data['cpu_time_ms']:>8.1f}ms  ({cat_data['pct_cpu']:>5.1f}%)\")\n",
    "        break\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Full report saved to: observer_reports/{observer.run_id}.json\")\n",
    "\n",
    "observer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
