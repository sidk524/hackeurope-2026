{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini GPT Transformer\n",
    "\n",
    "A character-level GPT language model trained on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# observer.py lives in the parent directory (neural_network/)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Observer, ObserverConfig\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# observer.py lives in the parent directory (neural_network/)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n",
    "from observer import Observer, ObserverConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Dataset and model paths\n",
    "DATASET_NAME = \"input_childSpeech_trainingSet.txt\"\n",
    "MODEL_NAME = os.path.join(\"models\", \"model_checkpoint.pt\")\n",
    "LOAD_MODEL = False\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "block_size = 128\n",
    "max_iters = 1\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "USE_BIAS_IN_ATTENTION = False\n",
    "USE_SKIP_CONNECTIONS = True\n",
    "\n",
    "seed = 1337\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Configure which telemetry channels to observe ──\nobserver_config = ObserverConfig(\n    track_profiler=True,\n    track_memory=True,\n    track_throughput=True,\n    track_loss=True,\n    track_console_logs=True,\n    track_error_logs=True,\n    track_hyperparameters=True,\n    track_system_resources=True,\n    profile_at_step=0,  # profile on the first batch of each epoch\n    profiler_group_by_stack_n=5,\n)\n\n# ── Initialize Observer ──\nobserver = Observer(\n    api_key=\"your-api-key-here\",\n    project_id=\"mini-gpt-experiment\",\n    config=observer_config,\n    run_name=f\"childSpeech_{n_embd}emb_{n_layer}L_{n_head}H\",\n)\n\n# ── Log hyperparameters ──\nobserver.log_hyperparameters({\n    \"dataset\": DATASET_NAME,\n    \"batch_size\": batch_size,\n    \"block_size\": block_size,\n    \"max_iters\": max_iters,\n    \"eval_interval\": eval_interval,\n    \"learning_rate\": learning_rate,\n    \"n_embd\": n_embd,\n    \"n_head\": n_head,\n    \"n_layer\": n_layer,\n    \"dropout\": dropout,\n    \"use_bias_in_attention\": USE_BIAS_IN_ATTENTION,\n    \"use_skip_connections\": USE_SKIP_CONNECTIONS,\n    \"seed\": seed,\n    \"device\": device,\n    \"eval_iters\": eval_iters,\n    \"optimizer\": \"AdamW\",\n})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Logging & Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "model_base_name = os.path.splitext(os.path.basename(MODEL_NAME))[0]\n",
    "log_filename = os.path.join(\"logs\", f\"{model_base_name}_{DATASET_NAME}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f\"Log file: {log_filename}\\n\")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading dataset: {DATASET_NAME}\")\n",
    "\n",
    "with open(DATASET_NAME, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "logger.info(f\"Total characters in dataset: {len(text):,}\")\n",
    "logger.info(f\"First 200 characters preview:\\n{text[:200]}\\n\")\n",
    "\n",
    "# Unique characters\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "logger.info(f\"Vocabulary size: {vocab_size}\")\n",
    "logger.info(f\"Unique characters: {''.join(chars)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character frequencies\n",
    "char_counts = Counter(text)\n",
    "logger.info(\"Top 5 Character frequencies:\")\n",
    "for char, count in char_counts.most_common(5):\n",
    "    logger.info(f\"'{char}': {count}\")\n",
    "\n",
    "# Most used words\n",
    "words = text.split()\n",
    "word_counts = Counter(words)\n",
    "logger.info(\"Most common 5 words:\")\n",
    "for word, count in word_counts.most_common(5):\n",
    "    logger.info(f\"'{word}': {count}\")\n",
    "\n",
    "unique_words = len(word_counts)\n",
    "logger.info(f\"Total unique words in dataset: {unique_words}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding & Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character-to-integer mapping\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "# Train/val split\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "logger.info(f\"Training set size: {len(train_data):,} characters\")\n",
    "logger.info(f\"Validation set size: {len(val_data):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = None\n",
    "if LOAD_MODEL:\n",
    "    logger.info(f\"\\nLoading existing model from: {MODEL_NAME}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_NAME, map_location=device)\n",
    "\n",
    "        vocab_size = checkpoint[\"vocab_size\"]\n",
    "        n_embd = checkpoint[\"n_embd\"]\n",
    "        n_head = checkpoint[\"n_head\"]\n",
    "        n_layer = checkpoint[\"n_layer\"]\n",
    "        block_size = checkpoint[\"block_size\"]\n",
    "        dropout = checkpoint[\"dropout\"]\n",
    "        USE_BIAS_IN_ATTENTION = checkpoint[\"use_bias\"]\n",
    "        USE_SKIP_CONNECTIONS = checkpoint[\"use_skip\"]\n",
    "        stoi = checkpoint[\"stoi\"]\n",
    "        itos = checkpoint[\"itos\"]\n",
    "\n",
    "        logger.info(f\"Loaded model configuration:\")\n",
    "        logger.info(f\"  Vocabulary size: {vocab_size}\")\n",
    "        logger.info(f\"  Embedding dimension: {n_embd}\")\n",
    "        logger.info(f\"  Attention heads: {n_head}\")\n",
    "        logger.info(f\"  Layers: {n_layer}\")\n",
    "        logger.info(f\"  Block size: {block_size}\")\n",
    "        logger.info(f\"  Previous train loss: {checkpoint['train_loss']:.4f}\")\n",
    "        logger.info(f\"  Previous val loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.info(f\"Error: Model file '{MODEL_NAME}' not found!\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    \"\"\"Generate a small batch of data of inputs x and targets y.\"\"\"\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\"One head of self-attention.\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=USE_BIAS_IN_ATTENTION)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=USE_BIAS_IN_ATTENTION)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=USE_BIAS_IN_ATTENTION)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)    # (B,T,hs)\n",
    "        q = self.query(x)  # (B,T,hs)\n",
    "        # Compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5  # (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        # Weighted aggregation of values\n",
    "        v = self.value(x)  # (B,T,hs)\n",
    "        out = wei @ v      # (B, T, hs)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multiple heads of self-attention in parallel.\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\"A simple linear layer followed by a non-linearity.\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: communication followed by computation.\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if USE_SKIP_CONNECTIONS:\n",
    "            x = x + self.sa(self.ln1(x))\n",
    "            x = x + self.ffwd(self.ln2(x))\n",
    "        else:\n",
    "            x = self.sa(self.ln1(x))\n",
    "            x = self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embd, n_head=n_head) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)                          # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # (T,C)\n",
    "        x = tok_emb + pos_emb  # (B,T,C)\n",
    "        x = self.blocks(x)     # (B,T,C)\n",
    "        x = self.ln_f(x)       # (B,T,C)\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]       # (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Observer] Model registered | 818,472 params (0.82M) | 72 param layers\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Model Configuration:\")\n",
    "logger.info(f\"Embedding dimension (n_embd): {n_embd}\")\n",
    "logger.info(f\"Number of attention heads (n_head): {n_head}\")\n",
    "logger.info(f\"Number of layers (n_layer): {n_layer}\")\n",
    "logger.info(f\"Block size (context length): {block_size}\")\n",
    "logger.info(f\"Batch size: {batch_size}\")\n",
    "logger.info(f\"Dropout: {dropout}\")\n",
    "logger.info(f\"Use bias in attention: {USE_BIAS_IN_ATTENTION}\")\n",
    "logger.info(f\"Use skip connections: {USE_SKIP_CONNECTIONS}\")\n",
    "logger.info(f\"Device: {device}\")\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "if LOAD_MODEL and checkpoint is not None:\n",
    "    m.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    logger.info(\"Model weights loaded successfully!\")\n",
    "\n",
    "num_params = sum(p.numel() for p in m.parameters())\n",
    "logger.info(f\"\\nTotal parameters: {num_params:,} ({num_params/1e6:.2f}M)\")\n",
    "\n",
    "# Register model with the observer (attaches activation & attention hooks,\n",
    "# captures architecture map with per-layer param counts)\n",
    "observer.register_model(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nif LOAD_MODEL:\n    logger.info(\"\\nSkipping training (LOAD_MODEL is set)\")\n    logger.info(\"Proceeding directly to evaluation...\\n\")\n    losses = (\n        {\"train\": checkpoint[\"train_loss\"], \"val\": checkpoint[\"val_loss\"]}\n        if checkpoint\n        else {}\n    )\nelse:\n    logger.info(\"Starting training...\")\n    training_start_time = time.time()\n\n    # ── Epoch-based training with Observer integration ──\n    # Each epoch = eval_interval steps (or remaining steps for the last epoch)\n    steps_per_epoch = min(eval_interval, max_iters) if eval_interval > 0 else max_iters\n    num_epochs = max(1, (max_iters + steps_per_epoch - 1) // steps_per_epoch)\n    global_step = 0\n    losses = {}\n\n    for epoch in range(num_epochs):\n        epoch_steps = min(steps_per_epoch, max_iters - global_step)\n\n        for step in range(epoch_steps):\n            xb, yb = get_batch(\"train\")\n\n            # obs.should_profile() checks config.profile_at_step\n            if observer.should_profile(step):\n                logits, loss = observer.profile_step(model, xb, yb)\n                optimizer.step()\n                optimizer.zero_grad(set_to_none=True)\n            else:\n                logits, loss = model(xb, yb)\n                optimizer.zero_grad(set_to_none=True)\n                loss.backward()\n                optimizer.step()\n\n            observer.step(\n                epoch, step, loss,\n                batch_size=batch_size, seq_length=block_size,\n            )\n            global_step += 1\n\n        # Evaluate at end of epoch\n        losses = estimate_loss()\n        elapsed = time.time() - training_start_time\n        logger.info(\n            f\"Epoch {epoch} (step {global_step}/{max_iters}): \"\n            f\"train loss {losses['train']:.4f}, val loss {losses['val']:.4f} \"\n            f\"(elapsed: {elapsed:.1f}s)\"\n        )\n\n        # Finalize epoch — collects memory, throughput, profiler data, system stats\n        epoch_report = observer.end_epoch(epoch, val_metrics={\n            \"val_loss\": losses[\"val\"],\n            \"train_loss_eval\": losses[\"train\"],\n        })\n\n    training_end_time = time.time()\n    training_time = training_end_time - training_start_time\n    logger.info(\n        f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)!\"\n    )"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_MODEL:\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"n_embd\": n_embd,\n",
    "            \"n_head\": n_head,\n",
    "            \"n_layer\": n_layer,\n",
    "            \"block_size\": block_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"use_bias\": USE_BIAS_IN_ATTENTION,\n",
    "            \"use_skip\": USE_SKIP_CONNECTIONS,\n",
    "            \"stoi\": stoi,\n",
    "            \"itos\": itos,\n",
    "            \"train_loss\": losses[\"train\"].item(),\n",
    "            \"val_loss\": losses[\"val\"].item(),\n",
    "        },\n",
    "        MODEL_NAME,\n",
    "    )\n",
    "    logger.info(f\"Model saved to {MODEL_NAME}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observer Report\n",
    "\n",
    "Export all collected epoch-by-epoch data: profiler ops, gradient health, activation stats,\n",
    "weight evolution, memory footprint, throughput, attention entropy, and system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Observer] Report exported -> observer_reports/mini-gpt-experiment_childSpeech_128emb_4L_4H.json\n",
      "[Observer] Observer closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OBSERVER SUMMARY\n",
      "============================================================\n",
      "Total epochs recorded:  1\n",
      "Total training time:    232.83s\n",
      "\n",
      "Loss trend:\n",
      "  First epoch:  3.7395\n",
      "  Last epoch:   3.7395\n",
      "  Best:         3.7395\n",
      "  Improved:     False\n",
      "\n",
      "Gradient health:\n",
      "  Epochs with issues:  0\n",
      "  Total issues:        0\n",
      "\n",
      "Avg throughput:  35 tokens/sec\n",
      "\n",
      "Profiler highlight:\n",
      "  Top operation:       model_forward\n",
      "  Top op % of total:   33.3%\n",
      "  Fwd/Bwd time ratio:  6.4281\n",
      "\n",
      "============================================================\n",
      "PROFILER: OPERATION CATEGORIES (last epoch)\n",
      "============================================================\n",
      "  other                   1260.5ms  ( 59.7%)\n",
      "  forward_pass             702.8ms  ( 33.3%)\n",
      "  matrix_ops                78.8ms  (  3.7%)\n",
      "  backward_pass             40.5ms  (  1.9%)\n",
      "  softmax                    9.2ms  (  0.4%)\n",
      "  normalization              8.5ms  (  0.4%)\n",
      "  dropout                    6.2ms  (  0.3%)\n",
      "  loss                       2.4ms  (  0.1%)\n",
      "  activation_fn              1.2ms  (  0.1%)\n",
      "  embedding                  1.1ms  (  0.1%)\n",
      "\n",
      "============================================================\n",
      "GRADIENT TOTAL NORMS (per epoch)\n",
      "============================================================\n",
      "  Epoch   0:  norm=0.0000  [healthy]\n",
      "============================================================\n",
      "Full report saved to: observer_reports/mini-gpt-experiment_childSpeech_128emb_4L_4H.json\n"
     ]
    }
   ],
   "source": [
    "# Export full observer report to JSON\n",
    "report = observer.export(os.path.join(\"observer_reports\", f\"{observer.run_id}.json\"))\n",
    "\n",
    "# ── Print summary ──\n",
    "summary = report[\"summary\"]\n",
    "print(\"=\" * 60)\n",
    "print(\"OBSERVER SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total epochs recorded:  {summary.get('total_epochs', 0)}\")\n",
    "print(f\"Total training time:    {summary.get('total_duration_s', 0):.2f}s\")\n",
    "\n",
    "if \"loss_trend\" in summary:\n",
    "    lt = summary[\"loss_trend\"]\n",
    "    print(f\"\\nLoss trend:\")\n",
    "    print(f\"  First epoch:  {lt['first']:.4f}\")\n",
    "    print(f\"  Last epoch:   {lt['last']:.4f}\")\n",
    "    print(f\"  Best:         {lt['best']:.4f}\")\n",
    "    print(f\"  Improved:     {lt['improved']}\")\n",
    "\n",
    "if \"gradient_health\" in summary:\n",
    "    gh = summary[\"gradient_health\"]\n",
    "    print(f\"\\nGradient health:\")\n",
    "    print(f\"  Epochs with issues:  {gh['epochs_with_issues']}\")\n",
    "    print(f\"  Total issues:        {gh['total_issues']}\")\n",
    "\n",
    "if \"avg_tokens_per_sec\" in summary:\n",
    "    print(f\"\\nAvg throughput:  {summary['avg_tokens_per_sec']:.0f} tokens/sec\")\n",
    "\n",
    "if \"profiler_highlight\" in summary:\n",
    "    ph = summary[\"profiler_highlight\"]\n",
    "    print(f\"\\nProfiler highlight:\")\n",
    "    print(f\"  Top operation:       {ph.get('top_op', 'N/A')}\")\n",
    "    print(f\"  Top op % of total:   {ph.get('top_op_pct', 0):.1f}%\")\n",
    "    print(f\"  Fwd/Bwd time ratio:  {ph.get('fwd_bwd_ratio', 'N/A')}\")\n",
    "\n",
    "# ── Print per-epoch profiler categories ──\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROFILER: OPERATION CATEGORIES (last epoch)\")\n",
    "print(\"=\" * 60)\n",
    "for epoch_rec in reversed(report[\"epochs\"]):\n",
    "    if \"profiler\" in epoch_rec:\n",
    "        cats = epoch_rec[\"profiler\"].get(\"operation_categories\", {})\n",
    "        for cat_name, cat_data in sorted(cats.items(), key=lambda x: -x[1][\"cpu_time_ms\"]):\n",
    "            print(f\"  {cat_name:<20s}  {cat_data['cpu_time_ms']:>8.1f}ms  ({cat_data['pct_cpu']:>5.1f}%)\")\n",
    "        break\n",
    "\n",
    "# ── Print per-epoch gradient norms ──\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GRADIENT TOTAL NORMS (per epoch)\")\n",
    "print(\"=\" * 60)\n",
    "for epoch_rec in report[\"epochs\"]:\n",
    "    if \"gradients\" in epoch_rec:\n",
    "        g = epoch_rec[\"gradients\"]\n",
    "        health = g.get(\"health\", \"?\")\n",
    "        print(f\"  Epoch {epoch_rec['epoch']:>3d}:  norm={g['total_norm']:.4f}  [{health}]\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Full report saved to: observer_reports/{observer.run_id}.json\")\n",
    "\n",
    "# Clean up observer hooks\n",
    "observer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generated text sample:\")\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_text = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "logger.info(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_on_test_file(\n",
    "    model, filename, stoi, block_size, device, batch_size, eval_iters=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a test file and calculate the loss.\n",
    "    Handles characters not in vocabulary by skipping them.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"\\nEvaluating on: {filename}\")\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            test_text = f.read()\n",
    "\n",
    "        logger.info(f\"Test file length: {len(test_text):,} characters\")\n",
    "\n",
    "        test_encoded = []\n",
    "        skipped_chars = set()\n",
    "        for c in test_text:\n",
    "            if c in stoi:\n",
    "                test_encoded.append(stoi[c])\n",
    "            else:\n",
    "                skipped_chars.add(c)\n",
    "\n",
    "        if skipped_chars:\n",
    "            logger.info(\n",
    "                f\"Warning: Skipped {len(skipped_chars)} characters not in vocabulary: {skipped_chars}\"\n",
    "            )\n",
    "\n",
    "        test_data = torch.tensor(test_encoded, dtype=torch.long)\n",
    "        logger.info(f\"Encoded test data length: {len(test_data):,} tokens\")\n",
    "\n",
    "        if len(test_data) <= block_size:\n",
    "            logger.info(\"Warning: Test data too short for evaluation\")\n",
    "            return None\n",
    "\n",
    "        model.eval()\n",
    "        losses = []\n",
    "\n",
    "        num_batches = min(eval_iters, len(test_data) // block_size)\n",
    "        for _ in range(num_batches):\n",
    "            ix = torch.randint(len(test_data) - block_size, (batch_size,))\n",
    "            x = torch.stack([test_data[i : i + block_size] for i in ix])\n",
    "            y = torch.stack([test_data[i + 1 : i + block_size + 1] for i in ix])\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits, loss = model(x, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        if losses:\n",
    "            avg_loss = sum(losses) / len(losses)\n",
    "            logger.info(f\"Average loss on {filename}: {avg_loss:.4f}\")\n",
    "            return avg_loss\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.info(f\"Error: File {filename} not found\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error evaluating on {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Evaluating on Test Sets\")\n",
    "\n",
    "test_loss_child = evaluate_on_test_file(\n",
    "    model, \"input_childSpeech_testSet.txt\", stoi, block_size, device, batch_size, eval_iters=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loss_shakespeare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_loss_child:\n\u001b[1;32m     27\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss (Child Speech): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss_child\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtest_loss_shakespeare\u001b[49m:\n\u001b[1;32m     29\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss (Shakespeare): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss_shakespeare\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loss_shakespeare' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_baseline_loss(text, stoi):\n",
    "    \"\"\"\n",
    "    Calculate baseline loss using uniform character distribution.\n",
    "    This is the loss if the model just guessed randomly.\n",
    "    \"\"\"\n",
    "    char_counts = {}\n",
    "    total_chars = 0\n",
    "    for c in text:\n",
    "        if c in stoi:\n",
    "            char_counts[c] = char_counts.get(c, 0) + 1\n",
    "            total_chars += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for count in char_counts.values():\n",
    "        prob = count / total_chars\n",
    "        entropy -= prob * math.log(prob)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "logger.info(\"Baseline Comparison:\")\n",
    "baseline_train = calculate_baseline_loss(text, stoi)\n",
    "logger.info(f\"Baseline loss (uniform distribution): {baseline_train:.4f}\")\n",
    "logger.info(f\"Training loss: {losses['train']:.4f}\")\n",
    "logger.info(f\"Validation loss: {losses['val']:.4f}\")\n",
    "if test_loss_child:\n",
    "    logger.info(f\"Test loss (Child Speech): {test_loss_child:.4f}\")\n",
    "if test_loss_shakespeare:\n",
    "    logger.info(f\"Test loss (Shakespeare): {test_loss_shakespeare:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "logger.info(\n",
    "    f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}